# RTX 5090 本地部署 **Qwen3-Embedding-8B** 模型初始分数

| 配置项       | 说明                                                      |
| ------------ | --------------------------------------------------------- |
| **评估平台** | MTEB v1.38.33                                             |
| **模型路径** | `/mnt/volume1/shared/models/hub/Qwen3/Qwen3-Embedding-8B` |
| **评估任务** | AILAStatutes（法律条文检索）                              |
| **硬件环境** | NVIDIA GeForce RTX 5090 · CUDA                            |
| **批大小**   | _未明确（可补充）_                                        |
| **运行时间** | ≈ 750 秒                                                  |

---

## 1. 原始 JSON 结果

```json
{
  "dataset_revision": "ebfcd844eadd3d667efa3c57fc5c8c87f5c2867e",
  "task_name": "AILAStatutes",
  "mteb_version": "1.38.33",
  "scores": {
    "test": [
      {
        "ndcg_at_1": 0.84,
        "ndcg_at_3": 0.71802,
        "ndcg_at_5": 0.67192,
        "ndcg_at_10": 0.79863,
        "ndcg_at_20": 0.84306,
        "ndcg_at_100": 0.85051,
        "ndcg_at_1000": 0.85051,
        "map_at_1": 0.20467,
        "map_at_3": 0.43011,
        "map_at_5": 0.53581,
        "map_at_10": 0.65647,
        "map_at_20": 0.69031,
        "map_at_100": 0.69382,
        "map_at_1000": 0.69382,
        "recall_at_1": 0.20467,
        "recall_at_3": 0.462,
        "recall_at_5": 0.633,
        "recall_at_10": 0.87133,
        "recall_at_20": 0.978,
        "recall_at_100": 1.0,
        "recall_at_1000": 1.0,
        "precision_at_1": 0.84,
        "precision_at_3": 0.66667,
        "precision_at_5": 0.54,
        "precision_at_10": 0.376,
        "precision_at_20": 0.212,
        "precision_at_100": 0.0434,
        "precision_at_1000": 0.00434,
        "mrr_at_1": 0.84,
        "mrr_at_3": 0.92,
        "mrr_at_5": 0.92,
        "mrr_at_10": 0.92,
        "mrr_at_20": 0.92,
        "mrr_at_100": 0.92,
        "mrr_at_1000": 0.92,
        "main_score": 0.79863,
        "hf_subset": "default",
        "languages": ["eng-Latn"]
      }
    ]
  },
  "evaluation_time": 750.0340869426727,
  "kg_co2_emissions": null
}
```

> **main_score = nDCG @10 = 0.79863**；其余指标详见下表与分析。

---

## 2. 关键指标一览

| 指标 / k      | **@1**     | **@3** | **@5** | **@10**    | **@20**    |
| ------------- | ---------- | ------ | ------ | ---------- | ---------- |
| **nDCG**      | 0.8400     | 0.7180 | 0.6719 | **0.7986** | 0.8431     |
| **MAP**       | 0.2047     | 0.4301 | 0.5358 | 0.6565     | 0.6903     |
| **Recall**    | 0.2047     | 0.4620 | 0.6330 | 0.8713     | **0.9780** |
| **Precision** | **0.8400** | 0.6667 | 0.5400 | 0.3760     | 0.2120     |
| **MRR**       | 0.8400     | 0.9200 | 0.9200 | 0.9200     | 0.9200     |

<sub>完整 @100 / @1000 指标见 JSON。</sub>

---

## 3. 分析与结论

| 维度             | 现象                                            | 相比 0.6 B        | 结论                               |
| ---------------- | ----------------------------------------------- | ----------------- | ---------------------------------- |
| **核心排序质量** | nDCG @10 = **0.799**                            | ↑ +0.054          | 整体相关性显著提升，逼近“优秀”水平 |
| **首条命中**     | nDCG @1 = 0.84<br>Precision @1 = 0.84           | ↑ +0.02           | 用户“一击即中”体验更好             |
| **覆盖率**       | Recall @20 = 0.978<br>Recall @10 = 0.871        | ↑ ≈ +0.07 / +0.06 | 前 20 条几乎覆盖全部相关法规       |
| **长尾精度**     | Precision @20 = 0.212<br>Precision @100 = 0.043 | ≈                 | 深排仍偏“放水”，需抑制噪声         |
| **基线增益**     | nauc_ndcg / map / mrr diff1 多数 > 0            | ↑                 | 与官方基线差距进一步拉大           |

### 关键洞察

- **模型规模带来稳健收益**
  8 B 在所有 nDCG 切点升级 5–8 pp，反映更强语义对齐能力。

- **召回高但精度衰减曲线未改**
  召回 ≈ 1.0 → Precision 自 @10 起快速下降，显示**长尾噪声**仍待治理。

- **MRR 常年 0.92**
  首相关文档几乎总出现在前三位，首屏体验极佳。

---

## 4. 优化建议（面向 8 B）

| 优先级 | 动作                                                  | 预期收益                        |
| :----: | ----------------------------------------------------- | ------------------------------- |
|   ⭐   | **Top-k 精排**：对前 50 条用 Cross-Encoder/LLM rerank | Precision @10 ↑ → ≈ 0.45 – 0.50 |
|   ⭐   | **分数阈值 / 早停**：按 nDCG 曲线拐点截断             | 列表降噪、提升可读性            |
|  ⭐⭐  | **硬规则混合**：法规条号、关键词布尔过滤              | MAP @20+ 再提升                 |
|  ⭐⭐  | **难例对比微调**：采集错位 Top-3 做 Pairwise 调整     | nDCG @3 ↑，首屏更稳             |
|   ⭐   | **性能调优**：750 s → FP16 / TensorRT 等              | 推理成本 ↓，响应 ↑              |

---

## 5. 总结

> **Qwen3-Embedding-8B** 在法律条文检索中相对 0.6 B **实现显著排序增益**：
>
> - nDCG @10 ≈ 0.80，Precision @1 = 0.84
> - 已达生产可用水平
> - 长尾 Precision 偏低，建议结合轻量级重排序与阈值裁剪，兼顾高召回与体验。

> 未来可通过更精细的微调与后处理策略，进一步提升模型在法律领域的应用效果。
