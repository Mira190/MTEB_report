## 1. MTEB AILAStatutes 数据集处理与理解

**MTEB AILAStatutes** 数据集是法律文本检索的基准，其核心在于评估模型在法律情境下识别相关法规的能力。

### 数据集结构与内容特征

- **用途**：文本检索任务，旨在根据法律问题（查询）检索相关法律条款（文档）。
- **构成**：包含 `test` 分割，由 `query-id`、`corpus-id` 和 `score`（相关性判断，通常为 1 表示相关）组成。
- **规模**：82 个独特的法规文档和 50 个独特的查询。每个查询平均有 2 到 5 个相关文档。
- **语言与领域**：英文法律文本，来源于 2019 年 FIRE AILA（人工智能法律援助）赛道的“法规检索”任务。查询是匿名化的印度法院案例事实，法规来自汤森路透 Westlaw 印度。
- **文本长度**：

  - 文档平均约 1975 字符，最长可达 26039 字符；
  - 查询平均约 3038 字符，最长可达 5936 字符。
  - 数据集包含**长篇、复杂的法律文本**，充满专业术语、复杂句式和潜在的引用关系。

### ndcg_at_10 评估指标

- **定义**：**归一化折损累计增益**（Normalized Discounted Cumulative Gain）在 Top 10。
- **目的**：评估检索系统对文档排序的质量，衡量相关文档是否排在更高位置。
- **原理**：相关性更高的文档若出现在结果列表的顶部，会获得更高的分数；位置越靠后的文档，其相关性分数会被对数函数折损。
- **范围**：0 到 1 之间，1 表示完美排序。
- **重要性**：对法律信息检索至关重要，因为用户通常只查看前几条结果，相关性排序直接影响用户找到所需法律信息的能力。

## 2. 数据集处理方式

1. **文本清洗与预处理**

   - 去除冗余信息：清理页眉、页脚、案例编号、引用格式等非核心检索信息。
   - 标准化格式：统一文本编码、去除特殊字符。
   - 句段或子句拆分（Passage Splitting）：将长文档拆分为更小的语义单元（段落、章节、条款），如按章节标题、段落标记或固定长度（带重叠）。
   - 识别关键实体：标注法律实体（如法律、案例、条款、日期、当事人），辅助后续特征工程。

2. **数据格式转换**
   确保 AILAStatutes 数据符合 Qwen3 Embedding 微调所需格式，通常是查询–文档对，带有相关性标签。

### 示例：原始与目标格式转换

#### 原始 AILAStatutes 格式（JSONL）

- **corpus.jsonl**（法规条文库）

  ```json
  {
    "id": "statute_001",
    "title": "合同法 第十条",
    "text": "当事人应当根据合同的性质和目的，履行诚信原则。"
  }
  ```

- **queries.jsonl**（检索查询）

  ```json
  { "id": "q_007", "query": "合同履行必须遵循什么原则？" }
  ```

- **qrels**（相关性标注，query – doc – label，label ∈ {0,1,2}）

  ```tsv
  q_007  statute_001  2
  q_007  statute_015  1
  q_007  statute_123  0
  ```

#### 目标微调格式示例

```json
{
  "query": "合同履行必须遵循什么原则？",
  "doc": "当事人应当根据合同的性质和目的，履行诚信原则。",
  "label": 2
}
```

- **query**：原始 `queries.jsonl` 中的 `query` 字段。
- **doc**：从 `corpus.jsonl` 中按 `id` 取出的 `text` 字段，也可拼接 `title` + `text`。
- **label**：对应的相关性打分（0 = 无关，1 = 部分相关，2 = 高度相关）。

---

## 3. 生成“硬负样本”三元组

当使用三元组对比损失（triplet loss 或 RankCTL）时，可将一个正例配若干负例：

```json
{
  "query": "合同履行必须遵循什么原则？",
  "positive_doc": "当事人应当根据合同的性质和目的，履行诚信原则。",
  "negative_doc": "未成年人进行合同订立应当有其法定代理人同意。"
}
```

- **negative_doc**：可从 label=0 的条文中随机抽取，或通过初步检索模型获取 hardest negatives。

> **Tip**：
>
> - **Pairwise**（单对带标签）适合 MarginMSE 或交叉熵回归，字段为 `query/doc/label`。
> - **Triplet**（正负对）适合对比损失，字段为 `query/positive_doc/negative_doc`。

---

## 4. 法律信息检索的挑战与嵌入模型优化方法

- **领域词汇与复杂性**：法律术语晦涩，句法复杂。
- **低词汇重叠**：查询与相关文档词汇重叠度低，但语义相关性高。
- **长文本处理**：法规文档篇幅长，上下文处理难。
- **数据稀缺**：高质量标注数据集稀少。
- **知识时效性**：法律不断变化，模型静态知识或跟不上。

### 优化策略

1. **领域自适应预训练（DAPT）**
   在大量未标注法律文本上继续预训练通用模型（如 Qwen3），学习法律领域模式。

2. **任务自适应预训练（TAPT）**
   在少量有监督或弱监督的检索数据上进一步预训练，学习检索特有模式。

3. **长文本嵌入技术**
   利用 ALiBi 等技术处理长序列，或分段嵌入并聚合。

4. **多粒度嵌入**
   生成篇章级、段落级、句子级嵌入，根据查询粒度匹配。

5. **混合检索系统**
   结合传统关键词检索（BM25）与语义嵌入检索，互补不足。

6. **Reranker 模型**
   初步检索后，用更复杂模型对 Top-K 结果进行二次排序。

---

## 5. 构建额外数据集：合成与公开数据集

### 5.1 LLM 合成数据集

利用 LLM（如 Qwen3-32B Instruct）生成合成查询–文档对，缓解数据稀缺：

- **角色扮演**：让 LLM 扮演法律研究员或普通用户。
- **明确任务**：定义生成查询或相关文档的目标。
- **上下文提供**：向 LLM 提供法律文档片段。
- **指定输出格式**：如 JSON、CSV，便于后续处理。
- **多样性**：鼓励多类型查询（事实性、解释性、比较性）。
- **Aspect-Guided Prompting**：按特定方面（条款、判例、概念、情境）生成。

#### 合成示例

**文档片段**：

> 《中华人民共和国民法典》
> 第一千一百六十五条 【过错责任原则】……
> 第一千一百六十六条 【无过错责任原则】……

**Prompt 示例 1（生成问题–答案对）**

```json
[
  {
    "query": "用户的民事权益受到侵害，在什么情况下行为人需要承担赔偿责任？",
    "relevant_documents": ["第一千一百六十五条"]
  },
  {
    "query": "如果法律明确规定了责任，即使当事人没有过失，是否仍需承担后果？",
    "relevant_documents": ["第一千一百六十六条"]
  }
]
```

**Prompt 示例 2（生成检索对）**

```json
[
  {
    "query": "某甲驾驶车辆不慎撞伤路人乙，乙可以根据哪些法律条文向甲主张赔偿？",
    "relevant_document_ids": ["第一千一百六十五条"]
  },
  {
    "query": "高空抛物砸伤他人，法律规定建筑物管理人有责任时是否依然要赔偿？",
    "relevant_document_ids": ["第一千一百六十六条"]
  },
  {
    "query": "法律未明确规定过错时是否就无责任？",
    "relevant_document_ids": ["第一千一百六十五条", "第一千一百六十六条"]
  }
]
```

### Prompt 示例 3（LLM 生成数据集 Prompt1）

你是一名法律数据合成工程师，需要生成多条 JSON 记录，每行包含 `query`、`doc`、`label`。

- `query`：自然语言提问；
- `doc`：对应法规全文；
- `label`：相关性评分（0/1/2）。

请根据下列法条片段，分别生成 3 条符合上述格式的样本，每条独立一行。

**法条库：**

1. “保险合同订立后，当事人未如实告知重大事项的，保险人可以解除合同。”
2. “机动车驾驶人饮酒后驾驶机动车的，由公安机关交通管理部门处罚。”
3. “借款合同以书面形式订立，当事人可以约定利率上下限。”

---

### Prompt 示例 4（LLM 生成数据集 Prompt2）

作为三元组数据生成器，请根据给定的查询，生成一条高度相关（label=2）和一条无关（label=0）的 JSON 记录，各自一行，字段同为 `query`、`doc`、`label`。

**查询：**  
“当事人饮酒后驾驶机动车应承担何种法律责任？”

**相关法条（正例）：**  
“机动车驾驶人饮酒后驾驶机动车的，由公安机关交通管理部门处罚。”

**无关法条（负例）：**  
“借款合同以书面形式订立，当事人可以约定利率上下限。”

---

合成后需 **去重与过滤**、**人工审核（抽样）**、**平衡性检查**。

### 5.2 公开获取的法律文本数据集

- **Pile of Law**：大规模英文法律语料。
- **EURLEX57K**：欧盟法律文档。
- **Cambridge Law Corpus (CLC)**：剑桥法律语料。
- **Super-SCOTUS**：美国最高法院判决。
- **MAUD**：美国反垄断法数据。
- **ContractNLI**：合同条款推理集。
- **HLDC**：印地语法律文档。
- **ILDC for CJPE**：印度法律文档。
- **国内来源**：中国法律文书网、北大法宝等。

**用途**：

- DAPT 预训练；
- 扩充相关性对用于 TAPT 或监督微调。

---

## 6. Qwen3 Embedding 的高级微调策略

1. **基础模型选择**：使用 Qwen3 Embedding 预训练模型。
2. **弱监督预训练（DAPT with Synthetic Data）**

   - 数据：Pile of Law + 合成查询–文档对（约 1.5 亿对）。
   - 损失：InfoNCE（对比学习）。

3. **高质量监督微调（TAPT & Fine-tuning）**

   - 数据：精选合成对（\~1200 万对）、公开检索数据集、AILAStatutes。
   - 指令遵循：在查询前加如 `"{Retrieve relevant legal statutes} {Query}<|endoftext|>"`。

4. **模型合并**：尝试 slerp 等技术融合不同阶段模型。
5. **参数高效微调（PEFT/LoRA）**：加速、降低内存消耗。

---

## 7. 冲击 MTEB AILAStatutes 排行榜的成功策略

- **大模型与多阶段训练**：基于大参数模型，分阶段预训练与微调。
- **大规模数据利用**：通用与领域专用语料共用；合成数据关键。
- **检索专项优化**：对比学习区分相关/无关对。
- **指令微调与多任务学习**：提升泛化能力。
- **长上下文处理**：强化长文本理解。
- **持续评估与迭代**：不断在目标数据集上评估并调整策略。

---

## 8. 迭代评估与优化计划

### 阶段一：基线建立与初步微调

1. **数据准备**

   - AILAStatutes 文档拆分与清理；
   - 合成数据生成（10–100 万对）；
   - 选定 DAPT 子集数据。

2. **模型初始化**：Qwen3 Embedding。
3. **初次 DAPT**：精选 DAPT 数据上进行。
4. **初步监督微调**：合成数据 + AILAStatutes（训练集）。
5. **基线评估**：在 AILAStatutes 测试集上测 nDCG\@10。

### 阶段二：性能分析与策略调整

1. **深入分析**

   - 错误分析（查询类型、长度、概念）；
   - 相关性得分分布；
   - 文档长度影响；
   - 召回与精度平衡。

2. **识别弱点**
3. **策略调整**

   - **数据增强**：优化提示、构建 harder negatives、引入更多公开数据；
   - **模型/参数**：调整拆分策略、超参数、指令模板；
   - **Reranker**：二次排序 Top-K 结果。

### 阶段三：迭代优化与冲刺

1. **反复循环**：数据准备 → 微调 → 评估 → 分析 → 调整。
2. **小批量改进**：每次迭代做针对性优化并记录结果。
3. **关注前沿**：跟踪排行榜及论文。
4. **最终冲刺**：精细超参搜索、模型集成/合并。

---
